<?xml version="1.0"?>
<launch>
  <!-- Parameter files -->
  <arg name="object_recognition_detection_euclidean_cluster_param_path"/>
  <arg name="object_recognition_detection_outlier_param_path"/>
  <arg name="object_recognition_detection_object_lanelet_filter_param_path"/>
  <arg name="object_recognition_detection_object_position_filter_param_path"/>
  <arg name="object_recognition_detection_pointcloud_map_filter_param_path"/>
  <arg name="object_recognition_prediction_map_based_prediction_param_path"/>
  <arg name="object_recognition_detection_object_merger_data_association_matrix_param_path"/>
  <arg name="object_recognition_detection_object_merger_distance_threshold_list_path"/>
  <arg name="object_recognition_detection_fusion_sync_param_path"/>
  <arg name="object_recognition_detection_roi_cluster_fusion_param_path"/>
  <arg name="object_recognition_detection_roi_pointcloud_fusion_param_path"/>
  <arg name="object_recognition_detection_roi_detected_object_fusion_param_path"/>
  <arg name="object_recognition_detection_lidar_model_param_path"/>
  <arg name="object_recognition_detection_radar_lanelet_filtering_range_param_path"/>
  <arg name="object_recognition_detection_radar_crossing_objects_noise_filter_param_path"/>
  <arg name="object_recognition_detection_radar_object_clustering_param_path"/>
  <arg name="object_recognition_detection_object_velocity_splitter_radar_param_path"/>
  <arg name="object_recognition_detection_object_velocity_splitter_radar_fusion_param_path"/>
  <arg name="object_recognition_detection_object_range_splitter_radar_param_path"/>
  <arg name="object_recognition_detection_object_range_splitter_radar_fusion_param_path"/>
  <arg name="object_recognition_tracking_multi_object_tracker_data_association_matrix_param_path"/>
  <arg name="object_recognition_tracking_multi_object_tracker_input_channels_param_path"/>
  <arg name="object_recognition_tracking_multi_object_tracker_node_param_path"/>
  <arg name="object_recognition_tracking_radar_object_tracker_data_association_matrix_param_path"/>
  <arg name="object_recognition_tracking_radar_object_tracker_tracking_setting_param_path"/>
  <arg name="obstacle_segmentation_ground_segmentation_param_path"/>
  <arg name="obstacle_segmentation_ground_segmentation_elevation_map_param_path"/>
  <arg name="object_recognition_detection_obstacle_pointcloud_based_validator_param_path"/>
  <arg name="object_recognition_detection_detection_by_tracker_param"/>
  <arg name="occupancy_grid_map_method"/>
  <arg name="occupancy_grid_map_param_path"/>
  <arg name="occupancy_grid_map_updater"/>
  <arg name="occupancy_grid_map_updater_param_path"/>
  <arg name="traffic_light_arbiter_param_path"/>
  <arg name="traffic_light_multi_camera_fusion_param_path"/>
  <arg name="lidar_detection_model"/>
  <arg name="sensor_model" description="sensor model name"/>

  <!-- ML model parameters -->
  <arg name="lidar_detection_model_type" default="$(eval &quot;'$(var lidar_detection_model)'.split('/')[0]&quot;)"/>
  <arg name="lidar_detection_model_name" default="$(eval &quot;'$(var lidar_detection_model)'.split('/')[1] if '/' in '$(var lidar_detection_model)' else ''&quot;)"/>
  <arg name="centerpoint_model_path" default="$(var data_path)/lidar_centerpoint"/>
  <arg name="transfusion_model_path" default="$(var data_path)/lidar_transfusion"/>
  <arg name="pointpainting_model_path" default="$(var data_path)/image_projection_based_fusion"/>

  <!-- Common parameters -->
  <arg name="input/pointcloud" default="/sensing/lidar/concatenated/pointcloud" description="The topic will be used in the detection module"/>
  <arg name="mode" default="camera_lidar_fusion" description="options: `camera_lidar_radar_fusion`, `camera_lidar_fusion`, `lidar_radar_fusion`, `lidar` or `radar`"/>
  <arg name="data_path" default="$(env HOME)/autoware_data" description="packages data and artifacts directory path"/>
  <arg name="lidar_detection_model_type" default="$(var lidar_detection_model_type)" description="options: `transfusion`, `centerpoint`, `pointpainting`, `apollo`, `clustering`"/>
  <arg name="lidar_detection_model_name" default="$(var lidar_detection_model_name)" description="options: `transfusion`, `centerpoint`, `centerpoint_tiny`, `centerpoint_sigma`, `pointpainting`"/>
  <arg name="image_raw0" default="/sensing/camera/camera0/image_rect_color" description="image raw topic name"/>
  <arg name="camera_info0" default="/sensing/camera/camera0/camera_info" description="camera info topic name"/>
  <arg name="detection_rois0" default="/perception/object_recognition/detection/rois0" description="detection rois output topic name"/>
  <arg name="image_raw1" default="/sensing/camera/camera1/image_rect_color"/>
  <arg name="camera_info1" default="/sensing/camera/camera1/camera_info"/>
  <arg name="detection_rois1" default="/perception/object_recognition/detection/rois1"/>
  <arg name="image_raw2" default="/sensing/camera/camera2/image_rect_color"/>
  <arg name="camera_info2" default="/sensing/camera/camera2/camera_info"/>
  <arg name="detection_rois2" default="/perception/object_recognition/detection/rois2"/>
  <arg name="image_raw3" default="/sensing/camera/camera3/image_rect_color"/>
  <arg name="camera_info3" default="/sensing/camera/camera3/camera_info"/>
  <arg name="detection_rois3" default="/perception/object_recognition/detection/rois3"/>
  <arg name="image_raw4" default="/sensing/camera/camera4/image_rect_color"/>
  <arg name="camera_info4" default="/sensing/camera/camera4/camera_info"/>
  <arg name="detection_rois4" default="/perception/object_recognition/detection/rois4"/>
  <arg name="image_raw5" default="/sensing/camera/camera5/image_rect_color"/>
  <arg name="camera_info5" default="/sensing/camera/camera5/camera_info"/>
  <arg name="detection_rois5" default="/perception/object_recognition/detection/rois5"/>
  <arg name="image_raw6" default="/sensing/camera/camera6/image_rect_color"/>
  <arg name="camera_info6" default="/sensing/camera/camera6/camera_info"/>
  <arg name="detection_rois6" default="/perception/object_recognition/detection/rois6"/>
  <arg name="image_raw7" default="/sensing/camera/camera7/image_rect_color"/>
  <arg name="camera_info7" default="/sensing/camera/camera7/camera_info"/>
  <arg name="detection_rois7" default="/perception/object_recognition/detection/rois7"/>
  <arg name="image_number" default="6" description="choose image raw number(1-8)"/>
  <arg name="pointcloud_container_name" default="pointcloud_container"/>

  <!-- Pipeline junctions -->
  <arg name="use_vector_map" default="true" description="use vector map in prediction"/>
  <arg name="use_pointcloud_map" default="true" description="use pointcloud map in detection"/>
  <arg name="use_low_height_cropbox" default="true" description="use low height crop filter in the euclidean clustering"/>
  <arg name="use_object_filter" default="true" description="use object filter"/>
  <arg name="objects_filter_method" default="lanelet_filter" description="options: `lanelet_filter` or `position_filter`"/>
  <arg name="use_roi_based_cluster" default="true" description="use roi_based_cluster in clustering"/>
  <arg name="use_low_intensity_cluster_filter" default="true" description="use low_intensity_cluster_filter in clustering"/>
  <arg name="use_image_segmentation_based_filter" default="false" description="use image_segmentation_based_filter in clustering"/>
  <arg name="use_empty_dynamic_object_publisher" default="true" description="if use_empty_dynamic_object_publisher:=true, /perception/object_recognition/objects topic has an empty DynamicObjectArray" />
  <arg name="use_object_validator" default="true" description="use obstacle_pointcloud based object validator"/>
  <arg name="objects_validation_method" default="obstacle_pointcloud" description="options: `obstacle_pointcloud` or `occupancy_grid`"/>
  <arg name="use_perception_online_evaluator" default="false" description="use perception online evaluator"/>
  <arg name="use_obstacle_segmentation_single_frame_filter" description="use single frame filter at the ground segmentation"/>
  <arg name="use_obstacle_segmentation_time_series_filter" description="use time series filter at the ground segmentation"/>

  <!-- Traffic light recognition parameters -->
  <arg name="use_traffic_light_recognition" default="false"/>
  <arg name="traffic_light_recognition/use_ml_detector" default="false" description="where ml model is used for TL detection"/>
  <arg name="traffic_light_recognition/ml_detection_model_type" default="fine_detection_model" description="select ml model for TL detection: fine_detection_model or whole_image_detection_model"/>
  <arg name="traffic_light_recognition/whole_image_detector_model_path" default="$(var data_path)/tensorrt_yolox"/>
  <arg name="traffic_light_recognition/whole_image_detector_model_name" default="yolox_s_car_ped_tl_detector_960_960_batch_1.onnx"/>
  <arg name="traffic_light_recognition/fusion_only" default="false"/>
  <arg name="all_traffic_light_camera" default="[camera6, camera7]" description="choose camera which use for traffic light recognition"/>
  <arg name="traffic_light_fine_detector_model_path" default="$(var data_path)/traffic_light_fine_detector" description="options: `tlr_yolox_s_batch_**`. The batch number must be either one of 1, 4, 6" />
  <arg name="traffic_light_fine_detector_model_name" default="tlr_car_ped_yolox_s_batch_6" description="options: `tlr_car_ped_yolox_s_batch_**`. The batch number must be either one of 1, 4, 6"/>
  <arg name="traffic_light_classifier_model_path" default="$(var data_path)/traffic_light_classifier" description="classifier onnx model path"/>
  <arg name="car_traffic_light_classifier_model_name" default="traffic_light_classifier_mobilenetv2_batch_6" description="options: `traffic_light_classifier_mobilenetv2_batch_*` or `traffic_light_classifier_efficientNet_b1_batch_*`. The batch number must be either one of 1, 4, 6" />
  <arg name="pedestrian_traffic_light_classifier_model_name" default="ped_traffic_light_classifier_mobilenetv2_batch_6" description="options: `ped_traffic_light_classifier_mobilenetv2_batch_*` or `ped_traffic_light_classifier_efficientNet_b1_batch_*`. The batch number must be either one of 1, 4, 6" />

  <!-- Whether to use detection by tracker -->
  <arg name="use_detection_by_tracker" default="true"/>

  <!-- Radar parameters -->
  <arg name="use_radar_tracking_fusion" default="true" description="if use_radar_tracking_fusion:=true, radar information is merged in tracking launch. Otherwise, radar information is merged in detection launch." />
  <arg name="input/radar" default="/sensing/radar/detected_objects"/>

  <!-- Object merger method: whether to enable multi-channel tracker merger -->
  <arg name="use_multi_channel_tracker_merger" default="false" description="if it is true, replace the multi step merger to multi-channel tracker merger."/>

  <!-- Downsample pointcloud for perception usage -->
  <arg name="downsample_perception_common_pointcloud" default="false"/>
  <arg name="common_downsample_voxel_size_x" default="0.05"/>
  <arg name="common_downsample_voxel_size_y" default="0.05"/>
  <arg name="common_downsample_voxel_size_z" default="0.05"/>

  <!-- Perception module -->
  <group>
    <push-ros-namespace namespace="perception"/>
    <!-- Perception common preprocess -->
    <let name="downsampled_pointcloud" value="/perception/common/pointcloud"/>
    <let name="perception_pointcloud" value="$(var input/pointcloud)" unless="$(var downsample_perception_common_pointcloud)"/>
    <let name="perception_pointcloud" value="$(var downsampled_pointcloud)" if="$(var downsample_perception_common_pointcloud)"/>
    <group if="$(var downsample_perception_common_pointcloud)">
      <push-ros-namespace namespace="common"/>
      <load_composable_node target="$(var pointcloud_container_name)">
        <composable_node pkg="autoware_pointcloud_preprocessor" plugin="autoware::pointcloud_preprocessor::PickupBasedVoxelGridDownsampleFilterComponent" name="pointcloud_downsample_node" namespace="">
          <remap from="input" to="$(var input/pointcloud)"/>
          <remap from="output" to="$(var downsampled_pointcloud)"/>
          <param name="voxel_size_x" value="$(var common_downsample_voxel_size_x)"/>
          <param name="voxel_size_y" value="$(var common_downsample_voxel_size_y)"/>
          <param name="voxel_size_z" value="$(var common_downsample_voxel_size_z)"/>
          <extra_arg name="use_intra_process_comms" value="true"/>
        </composable_node>
      </load_composable_node>
    </group>

    <!-- Object segmentation module -->
    <group>
      <push-ros-namespace namespace="obstacle_segmentation"/>
      <let name="sensor_launch_pkg" value="$(var sensor_model)_launch"/>
      <include file="$(find-pkg-share $(var sensor_launch_pkg))/launch/ground_segmentation/ground_segmentation.launch.py">
        <arg name="base_frame" value="base_link"/>
        <arg name="debug_mode" value="false"/>
        <arg name="use_intra_process" value="true"/>
        <arg name="use_multithread" value="true"/>
        <arg name="pointcloud_container_name" value="$(var pointcloud_container_name)"/>
        <arg name="input/pointcloud" value="$(var perception_pointcloud)"/>
        <arg name="obstacle_segmentation_ground_segmentation_param_path" value="$(var obstacle_segmentation_ground_segmentation_param_path)"/>
        <arg name="use_single_frame_filter" value="$(var use_obstacle_segmentation_single_frame_filter)"/>
        <arg name="use_time_series_filter" value="$(var use_obstacle_segmentation_time_series_filter)"/>
      </include>
    </group>

    <!-- Occupancy grid map module -->
    <!-- None -->

    <!-- Object recognition module -->
    <!-- None -->
    <!-- Detection module -->
    <!-- None -->

    <!-- Tracking module -->
    <!-- None -->

    <!-- Prediction module -->
    <!-- None -->

    <group if="$(var use_empty_dynamic_object_publisher)">
      <push-ros-namespace namespace="object_recognition"/>
      <node pkg="autoware_dummy_perception_publisher" exec="empty_objects_publisher" name="empty_objects_publisher" output="screen">
        <remap from="~/output/objects" to="/perception/object_recognition/objects"/>
      </node>
    </group>

    <!-- Traffic light module -->
    <!-- None -->
  </group>

  <!-- perception evaluator -->
  <group if="$(var use_perception_online_evaluator)">
    <include file="$(find-pkg-share autoware_perception_online_evaluator)/launch/perception_online_evaluator.launch.xml"/>
  </group>
</launch>
